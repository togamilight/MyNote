# 第 1 章 MySQL 架构与历史

## 1.1 MySQL 逻辑架构

* 第一层：客户端
* 第二层：服务器，包含大多数 MySQL 核心服务功能，如连接/线程处理、查询缓存、解析器、优化器以及所有内置函数，所有跨存储引擎功能（存储过程、触发器、视图）等
* 第三层：存储引擎，负责数据的存储和提取；服务器通过 API 与存储引擎通信，这些接口屏蔽了不同存储引擎间的差异；存储引擎 API 包含几十个底层函数，用于执行诸如“开始事务”、“根据主键提取一行记录”等操作，但存储引擎不会解析 SQL（InnoDB 会解析外键定义，因为 MySQL 服务器本身没有此功能），不同引擎不会通信，只是响应上层服务器的请求

### 连接管理与安全性

每个连接会在服务器进程中拥有一个线程，服务器负责缓存线程（线程池），用少量线程服务大量连接。  
客户端连接时，需要进行认证，基于**用户名、原始主机信息和密码**，若使用了安全套接字（SSL），还可用 X.509 证书认证；连接成功后，验证该用户是否具有执行某个特定查询的权限

### 优化与执行

对于 SELECT 语句，服务器会先检查查询缓存，若有则返回缓存的结果集，没有才执行下面的操作；  
服务器会解析查询，并创建内部数据结构（解析树），然后对其进行优化，包括重写查询、决定表的读取顺序、选择合适索引等；用户可通过特殊关键字提示(hint)优化器，影响其决策过程；  
优化器不关心表使用什么存储引擎，但引擎对于优化是有影响的，优化器会请求存储引擎提供容量或某个具体操作的开销信息，以及表数据的统计信息等

## 1.2 并发控制

### 读写锁

为了使大量并发操作时，写操作不会互相干扰，读操作不会读到错误数据，需要一个由两种类型的锁组成的锁系统来解决问题；  
这两类锁为**共享锁和排它锁**，也叫**读锁和写锁**：读锁共享，同一时刻可以有多个读操作；写锁排它，会阻塞其它所有锁，在写操作时不能进行其它写操作和读操作

### 锁粒度

锁粒度越小则并发性越高，但对锁的管理也越消耗系统资源；  
锁策略就是在锁的开销和数据的安全性之间寻求平衡，MySQL 提供了多种选择，每种存储引擎都可以实现自己的锁策略和锁粒度

#### 表锁

MySQL 中最基本的锁策略，开销最小，会锁定整张表；写锁优先级比读锁高，一个写锁请求可能被插入到读锁队列的前面；  
存储引擎管理自己的锁，但服务器还会使用各种表锁来实现不同目的，比如服务器会为 ALTER TABLE 之类的语句使用表锁，忽略存储引擎的锁策略

#### 行锁

最大程度支持并发，最大锁开销；只在存储引擎层实现（InnoDB 等），服务器层完全不了解存储引擎中的锁实现

## 1.3 事务

ACID：原子性 atomicity、一致性 consistency、隔离性 isolation、持久性 durability

事务也会增加系统开销，可根据业务是否需要事务处理来选择合适的存储引擎，以获得更高性能

### 隔离级别

设置隔离级别： `SET [SESSION] TRANSACTION ISOLATION LEVEL SERIALIZABLE;`  

| 隔离级别         | 脏读 | 不可重复读 | 幻读 | 加锁读 |
| ---------------- | ---- | ---------- | ---- | ------ |
| READ UNCOMMITTED | Y    | Y          | Y    | N      |
| READ COMMITTED   | N    | Y          | Y    | N      |
| REPEATABLE READ  | N    | N          | Y    | N      |
| SERIALIZABLE     | N    | N          | N    | Y      |

#### READ UNCOMMITTED 读未提交

事务中可读取到其它事务已修改但未提交的数据，即导致**脏读**；  
性能并没有好多少，会导致很多问题，一般很少使用

#### READ COMMITTED 读提交

大多数数据库的默认隔离级别，事务中只会读取到其它事务已提交的更改；  
但会导致**不可重复读**：事务中进行一次查询后，其它事务提交了更改，再次进行相同查询会得到不同结果

#### REPEATABLE READ 可重复读

MySQL 的默认隔离级别；  
保证了一个事务中多次读取同样记录的结果是一致的；  
但仍会导致**幻读**：在一个事务中读取某个范围内的记录，其它事务在该范围内插入新的记录，当再次读取该范围时，多出了新的记录（幻行）；InnoDB 和 XtraDB 存储引擎通过多版本并发控制(MVCC, Multiversion Concurrency Control)解决了幻读的问题

#### SERIALIZABLE 可串行化

最高隔离级别，强制事务串行执行，避免了幻读问题；  
会在读取的每一行数据上加锁，可能导致大量的超时和锁争用问题，除非很需要确保数据一致性且不需要并发时，才考虑使用

### 死锁

数据库系统实现了各种死锁检测和死锁超时机制来解决死锁。越复杂的系统，如 InnoDB，越能检测到死锁的循环依赖，并立即返回一个错误；另一种方法是当查询时间达到锁等待超时时放弃锁请求，但这不太好；  
InnoDB 目前的方法是，将持有最少行级排他锁的事务回滚；  
死锁发生后，只有部分或完全回滚其中一个事务才能打破，应用程序设计时必须考虑处理死锁，一般是重新执行因死锁回滚的事务

### 事务日志

帮助提高事务效率，存储引擎在修改表数据时只需要修改其内存拷贝，再把该修改行为记录到持久化在硬盘上的事务日志中，之后在后台慢慢将内存中被修改的数据持久化到硬盘中，称为**预写式日志**，修改数据需要写两次磁盘；  
事务日志采用追加的方式，写日志的操作是在磁盘上一小块区域内的顺序 I/O，相对随机 I/O 在磁盘多个区域移动磁头，效率更高；  
如果数据修改已记录到事务日志并持久化，但数据未写入磁盘，此时系统崩溃，存储引擎将在重启时自动恢复这部分修改的数据

### MySQL 中的事务

MySQL 提供了两种事务型存储引擎：InnoDB 和 NDB Cluster；此外还有一些第三方存储引擎也支持事务

#### 自动提交 AUTOCOMMIT

MySQL 使用 AUTOCOMMIT 变量来控制是否自动提交，默认为 ON(1)；  
启用时，除非显示开启事务，否则所有查询当做单独的事务直接提交；禁用时，当前会话的所有查询位于同一个事务中，直到提交或回滚，然后自动开启新事务；  
修改AUTOCOMMIT对非事务型的表没有影响，比如 MyISAM 或内存表，这些表由于没有事务概念，相当于一直处于自动提交模式；  
一些命令，如数据定义语言(DDL)的命令，在执行前会强制提交当前事务（如 ALTER TABLE,LOCK TABLES 等）

#### 在事务中混合使用存储引擎

服务器层不管理事务，事务由存储引擎管理，所以同一个事务混合使用存储引擎是不可靠的；  
如果混合使用了事务型和非事务型的表，正常提交时不会有问题；但需要回滚时，非事务型的表无法回滚，导致一致性被破坏，且很难修复；  
在非事务型的表上执行事务操作时，MySQL 不会发出提醒，只有回滚时才会发起警告  

#### 隐式和显示锁定

InnoDB 采用**两阶段锁定协议**，事务中，随时可执行锁定，锁只在事务结束时（提交或回滚）才会一起释放；根据隔离级别自动加锁是**隐式锁定**；  
支持通过特定语句**显示锁定**，这些语句不属于 SQL 规范，少用：
```SQL
SELECT ... LOCK IN SHARE MODE
SELECT ... FOR UPDATE
```
MySQL 也支持 LOCK TABLES 和 UNLOCK TABLES 语句，这是服务器层实现的，和存储引擎无关，且不能代替事务处理，不如 InnoDB 的行级锁，会影响性能；  
* LOCK TABLES 与事务之间相互影响会变得很复杂，建议**只**在处于事务中并禁止自动提交时，可以用一下

## 1.4 多版本并发控制

大多事务型存储引擎基于提升并发性能的考虑，不只实现行级锁，还有多版本并发控制(MVCC)，类似行级锁的一个变种，在很多情况下避免加锁操作，开销更低；MCVV 大多实现非阻塞的多操作，写操作也只锁定必要行；  
MVCC 通过保存数据在某个时间点的快照来决定，不管执行多久，同个事务看到的数据是一致的，只会看到该事务开始时刻就存在的数据；  

MVVC 的实现一般有**乐观和悲观**并发控制；InnoDB 是通过在每行记录后保存两个隐藏列来实现的：都是系统版本号，一列是行创建时的，一列是行过期或删除时的，每开始一个新事务，版本号自动递增，事务开始时的版本号作为事务的版本号；  
在 REPEATABLE READ 隔离级别下，MVCC的 具体操作如下：
* SELECT：根据两个条件检查每行记录：
  * 只查找版本小于或等于当前事务版本的行
  * 行的删除版本未定义或大于当前事务版本
* INSERT：为新插入的每一行保存当前事务版本号
* DELETE：为删除的每一行保存当前事务版本号
* UPDATE：插入一行新记录，为其保存当前事务版本号，同时保存当前事务版本号到原来的行作为行删除标识

InnoDB 的 MVCC 使大多数读操作不用加锁，使读操作很简单，性能很好，也保证只会读到符合标准的行；缺点是每行记录需要额外的存储空间，需要做更多行检查工作和一些额外的维护工作；  
MVCC 只在 REPEATABLE READ 和 READ COMMITED 隔离级别下工作，因为 READ UNCOMMITED 总是读取最新数据行，而 SERIALIZABLE 则对所有读取行加锁  

## 1.5 存储引擎

在文件系统中，MySQL 将每个数据库(schema)保存为数据目录下的一个子目录，创建表时，在数据库子目录下创建一个和表同名的 .frm 文件保存表的定义；因为 MySQL 使用文件系统的目录和文件来保存数据库和表的定义，大小写敏感与平台有关（Windows 中大小写不敏感，类 Unix 中大小写敏感）；不同的存储引擎保存数据和索引的方式不同，但表的定义是服务器层统一处理的；  

### InnoDB

MySQL 的默认事务型引擎，最重要，使用最广泛，被设计用来处理大量的短期事务（大部分情况正常提交，很少被回滚）；InnoDB 的性能和自动崩溃恢复特性，使它在非事务型存储的需求中也很流行；  

InnoDB 的数据存储在表空间中，每个表的数据和索引可以存放在单独的文件中；存储格式是平台独立的，数据和索引文件可以在任意平台间使用；    
采用 MVCC 来支持高并发，实现四个标准的隔离级别（默认是可重复读），并通过间隙锁（next-key locking）防止幻读，间隙锁使 InnoDB 不仅锁定查询涉及的行，还对索引中的间隙进行锁定，防止幻影行插入；
* TIP：查阅网上资料，发现解决幻读问题，快照读（普通的 SELECT）使用的是 MVCC，读取对应版本的数据快照；当前读（UPDATE, DELETE, INSERT, SELECT …  LOCK IN SHARE MODE, SELECT … FOR UPDATE）读取当前实际数据，使用间隙锁

InnoDB 表基于聚簇索引建立，索引结构与其它存储引擎有很大不同；聚簇索引对主键查询有很高的性能，但其二级索引（非主键索引）中必须包含主键列，所以如果主键列很大的话，其它所有索引都会很大，若表上索引较多，主键应尽量小；  

InnoDB 通过一些机制和工具支持热备份（MySQL Enterprise Backup，XtraBackup），其它存储引擎都不支持，要获取一致性视图需要停止对所有表的写入  

### MyISAM

是 MySQL5.1 及之前版本的默认引擎，不支持事务和行级锁，崩溃后无法安全恢复；  
对于只读数据，或表比较小、可以忍受修复（repair）操作，仍可以使用 MyISAM；  

其它的看书吧，好像没什么记的必要

### 其它内建引擎
看书

### 第三方引擎
看书

### 选择合适引擎

InnoDB 首选，其它看书

### 转换表的引擎

三种方法

#### ALTER TABLE

`ALTER TABLE table_name ENGINE=InnoDB;`

需要执行很久，会按行将数据从原表复制到新表中，复制期间可能会消耗系统所有的 I/O 能力，同时原表会加读锁；  
转换引擎后，会失去和原引擎相关的所有特性；  

#### 导入导出

使用 mysqldump 工具将数据导出到文件，然后修改文件中 CREATE TABLE 语句的存储引擎选项，修改表名（同一库中的表不能重名），要注意 mysqldump 默认会自动在 CREATE TABLE 语句前加上 DROP TABLE 语句，不注意可能导致数据丢失

#### 创建与查询

兼具第一种的高效第二种的安全，先创建一个新存储引擎的表，再用 INSERT...SELECT 语句插入数据；若数据量大，要考虑分批处理

# 第 4 章 Schema 与数据类型优化

## 4.1 选择优化的数据类型

* 更小的通常更好
    一般应该尽量使用可以正确存储数据的最小数据类型，占用更少磁盘、内存和 CPU 缓存，处理时需要的 CPU 周期更少；  
    但是要确保没有低估存储的值的范围，因为在 schema 中多个地方增加数据类型的范围很耗时、麻烦
* 简单就好
    简单数据类型的操作通常 CPU 周期更少，整型就不字符串操作代价更低；比如用 MySQL 内建类型而不是字符串来存储日期时间，用整型存储 IP 地址
* 尽量避免 NULL
    除非真的需要存储 NULL 值，否则最好指定列为 NOT NULL。因为 NULL 的列使得索引、索引统计和值比较都更复杂，更难优化；可为 NULL 的列使用更多存储空间，需要特殊处理，当该列被索引时，每个索引记录需要一个额外的字节，在 MyISAM 里甚至可能导致固定大小的索引变成可变大小的索引；不过将可为 NULL 的列改为 NOT NULL 带来的性能提升很小，不是很必要，但要在该列建索引的话，尽量为 NOT NULL；不过 InnoDB 用单独的位(bit)存储 NULL 值，对于稀疏数据（大多数为 NULL）有很好的空间效率

### 整数类型

TINYINT, SMALLINT, MEDIUMINT, INT, BIGINT (8, 16, 24, 32, 64 位)

整数类型都有可选的 UNSIGNED 属性，表示不允许负值，使用相同存储空间，性能不变，可使正数上限提高一倍；  
指定整数类型长度，如 INT(11)，只是规定一些交互工具（如命令行客户端）用来显示字符的个数，对于存储和计算没有意义

### 实数类型

FLOAT, DOUBLE, DECIMAL

FLOAT 和 DOUBLE 支持使用标准的浮点运行进行**近似**运算；  
DECIMAL 用于存储**精确**的小数，支持**精确**计算(Version >= 5.0）；CPU 不支持对 DECIMAL 的直接计算，MySQL 服务器实现了 DECIMAL 的高精度计算，但慢于 CPU 原生浮点计算;  
实数类型可以指定精度；DECIMAL 可以指定小数点前后允许的最大位数，会影响列占用的空间，5.0 及以上版本将数字打包保存到一个二进制字符串中（每 4 个字节存 9 个数字），最多允许 65 个数字（早期版本为 254 个，且保存在未压缩的字符串，每个数字一个字节）；
浮点列指定精度会使 MySQL 悄悄选择不同的数据类型或存储是对值进行取舍，这些精度定义是非标准的，**不推荐指定精度**； 
浮点类型存储同样范围的值，比 DECIMAL 使用更少的空间，FLOAT 用 4 个字节，DOUBLE 用 8 个字节；MySQL 使用 DOUBLE 作为内部浮点计算的类型；
DECIMAL 开销较大，只有需要精确计算小数时才用，也可用 BIGINT 代替，将小数乘以响应倍数转换成整数

### 字符串类型

每个字符串列可以定义自己的字符集和排序规则，很大程度上影响性能；字符串长度定义的是字符数，而不是字节数；数据如何存储取决于存储引擎，但填充和截取空格是在服务器层处理的  

#### VARCHAR

可变长字符串，比定长类型更节省空间，仅使用必要的空间，但如果表使用 `ROW_FORMAT=FIXED` 创建的话，每行都会使用定长存储；  
需要使用 1 或 2 个额外字节记录字符串的长度：列最大长度小于或等于 255 字节用 1 个字节表示，否则用两个字节；  
由于行是变长的，在更新时可能使行变得比原来长，会导致需要做额外的工作：当增长后页内没有空间可以存储时，MyISAM 会将行拆成不同的片段存储，InnoDB 则需要分裂页来使行可以放进页内；  
适合用 VARCHAR 的情况：字符串列的最大长度比平均长度大很多；列的更新很少，碎片不是问题；使用像 UTF-8 这样的复杂字符集，每个字符字节数不一定相同；  
在 5.0 及以上版本，VARCHAR 存储和检索时保留末尾空格；  
InnoDB 比较灵活，可以把过长的 VARCHAR 存储为 BLOB；  
尽量只使用刚好够用的长度，因为在内存中会分配固定大小的内存块来保存内部值，设定长度越大内存消耗越大，在使用内存临时表进行操作或排序时会很糟糕，利用磁盘临时表排序也一样糟糕    

#### CHAR

定长字符串，存储时删除所有末尾空格，会根据需要用空格填充以方便比较；  
适合存储很短的字符串，或者所有值都接近同一个长度，对于经常变更的数据，也比 VARCHAR 好，不容易产生碎片；对于很短的列，也比 VARCHAR 在空间上更有效率，因为 VARCHAR 需要多用一个字节记录长度；  
类似的类型有 BINARY 和 VARBINARY，存储二进制字符串，但存储的是字节码不是字符，填充 BINARY 用 \0（零字节）而不是空格，检索时不会去掉填充值；二进制比较按字节比较，更简单更快

#### BLOB 和 TEXT

用于存储庞大数据，分别采用二进制(BLOB)和字符(TEXT)方式存储；  
BLOB: TINYBLOB, SMALLBLOB, BLOB, MEDIUMBLOB, LONGBLOB；(SMALLBLOB=BLOB)  
TEXT: TINYTEXT, SMALLTEXT, TEXT, MEDIUMTEXT, LONGTEXT；(SMALLTEXT=TEXT)  

与其它类型不同，每个 BLOB 和 TEXT 值被当做独立对象处理，存储引擎在存储时通常会做特殊处理：当其值太大时，InnoDB 会使用专门的“外部”存储区域来存储，此时每个值在行内需要 1~4 个字节存储一个指针，在外部存储区域存储实际的值；  
BLOB 存储二进制数据，没有排序规则和字符集，TEXT 类型则有；  
BLOB/TEXT 列排序时只对最前 `max_sort_length` 字节进行比较，若还需缩短，可以设置 `max_sort_length`，也可使用 `SUBSTRING(column, length)`；  
无法对全部长度的字符串进行索引，也不能用索引消除排序；  

* Memory 不支持 BLOB/TEXT，如果查询使用了 BLOB/TEXT 列且需要使用隐式临时表，将不得不使用 MyISAM 磁盘临时表；可以使用 `SUBSTRING(column, length)` 将值转换为字符串，就可以使用内存临时表，但截取的长度不能超过 `max_heap_table_size` 或 `tmp_table_size`；如果 EXPLAIN 执行计划的 Extra 列包含 `Using temporary`，说明这个查询使用了隐式临时表

#### ENUM

枚举列可将多个不重复字符串存储成一个预定义合集，每个值在存储时保存为整数，根据枚举值的数量压缩到一或两个字节，并在表的 .frm 文件中保存“数字 - 字符串”映射关系的“查找表”；  
排序时将按照存储的整数进行排序，用 `FIELD()` 函数可使用字符串进行排序，但这样无法用索引消除排序，或者可以在定义时按字母顺序排列；  
缺点：字符串列表是固定的，添加和删除字符串都必须用 ALTER TABLE，除非只在列表末尾添加，这不需要重建整个表；  
缺点：整数到字符串的转换需要一些开销，若用 CHAR/VARCHAR 关联 ENUM 会比关联 CHAR/VARCHAR 慢

### 日期和时间类型

最小时间粒度为秒，但也可以使用微秒级的粒度进行临时计算

#### DATETIME

1001 年至 9999 年，精度为秒，把日期和时间封装到格式为 **YYYYMMDDHHmmSS** 的整数中，与时区无关，使用 8 个字节的存储空间；默认以一种可排序、无歧义的格式显示：**YYYY-MM-DD HH:mm:SS**，这是 ANSI 标准定义的日期时间表示方法；

#### TIMESTAMP

保存从 1970-01-01 午夜（格林威治标准时间）以来的秒数，与 UNIX 时间戳相同；只用 4 个字节的空间，范围比 DATETIME 小得多：1970 至 2038 年；  
`FROM_UNIXTIME()` 函数可将其转换为 DATETIME，`UNIX_TIMESTAMP()` 则相反；  
显示的值依赖于时区；  
TIMESTAMP 默认为 `NOT NULL`，且在更新和插入数据时，若不显式指定，第一个 TIMESTAMP 列的值将被设为当前时间；  

应尽量使用 TIMESTAMP，因为它比 DATETIME 空间效率更高；若要存储比秒更小粒度的时间，可以使用 BIGINT 或 DOUBLE

### 位数据类型

#### BIT

慎用！

5.0 以前，BIT 就是 TINYINT，但现在是完全不同的类型；BIT(num) 可通过 num 指定位数，最大 64；  
MyISAM 会打包存储所有的 BIT 列，所以 17 个单独的 BIT 列只需要 17 个位存储，即只需 3 个字节；Memory 和 InnoDB 等则用一个足够的最小整数来存储每个 BIT 列，不能节省空间；  
BIT 被当做字符串而不是数字类型，检索时，结果是包含二进制 0 或 1 值的字符串，而不是 ASCII 码的 "0" 或 "1"，显示的是该二进制转换为十进制后对应的 ASCII 码的字符串，但在数字上下文场景中（将其 +0）则为转换后的十进制数字，很怪，慎用；  
若要存储 true/false，除了 BIT 外还可使用可空的 `CHAR(0)` 列，可保存空值(NULL)或空字符串

#### SET

可合并保存多个 true/false 列，在内部以一系列打包的位的集合来表示，有效利用存储空间，有 `FIND_IN_SET()` 和 `FIELD()` 之类的函数方便查询；  
缺点是改变列定义需要 `ALTER TABLE`，代价较高（特别是对大表），一般来说也无法在 SET 列上通过索引查找

##### 在整数列上按位操作

使用一个整数包装一系列位可替代 SET，按位操作来使用，可在应用中为每个位定义名称常量来简化工作；  
优点是可以不使用 `ALTER TABLE` 改变字段代表的“枚举”值；缺点是查询语句更难写也更难理解

例子：保存权限的方位控制列表（ACL），每个位或 SET 元素代表一个值，如 CAN_READ, CAN_WRITE, CAN_DELETE;  
SET：
```SQL
CREATE TABLE acl(perms SET('CAN_READ', 'CAN_WRITE', 'CAN_DELETE') NOT NULL);
INSERT INTO acl(perms) VALUES('CAN_READ,CAN_DELETE');
SELECT perms FROM acl WHERE FIND_IN_SET('CAN_READ', perms);
```
整数：
```SQL
SET @CAN_READ := 1 << 0, @CAN_WRITE := 1 << 1, @CAN_DELETE := 1 << 2;
CREATE TABLE acl(perms TINYINT UNSIGNED NOT NULL DEFAULT 0);
INSERT INTO acl(perms) VALUES(@CAN_READ + @CAN_DELETE);
SELECT perms FROM acl WHERE perms & @CAN_READ;
```

### 选择标识符 (id)

确保所有关联表都是用相同类型，包括 `UNSIGNED` 这样的属性也相同，混用不同类型可能导致性能问题，比较操作时隐式类型转换也可能导致错误；  
在可满足值的范围需求，且预留未来增长空间的前提下，选择最小的数据类型；  

#### 整数类型

最好选择，很快，且可 `AUTO_INCREMENT`

#### ENUM/SET

很糟糕的选择，尽量避免

#### 字符串类型

尽量避免，很消耗空间，且通常比数字类型慢，特别是 MyISAM 中，它默认对字符串使用压缩索引，会导致查询很慢；  
对于 MD5(), SHA1(), UUID() 产生的随机字符串，会任意分布在很大的空间内，会导致 INSERT 以及一些 SELECT 语句很慢：
* 因为插入值会随机写到索引的不同位置，所以使 INSERT 语句更慢，会导致页分裂，磁盘随机访问，以及对于聚簇存储引擎产生聚簇索引碎片
* SELECT 语句更慢，因为逻辑上相邻的行会分布在磁盘和内存的不同位置
* 随机值导致**缓存**对所有类型的查询语句效果都很差，因为会使缓存赖以工作的**访问局部性原理**失效；如果整个数据集都一样“热”，缓存任何一部分都没有好处；如果工作集比内存大，缓存将会有很多刷新和不命中

如果存储 UUID，应移除 "-" 符号，最好用 UNHEX() 函数将其转换为 16 字节的数字，并存储在 BINARY(16) 的列中，检索时通过 HEX() 函数来格式化为十六进制；UUID 与 SHA1 等加密散列不同，虽然分布不均匀，但还是有一定顺序

### 特殊类型数据

某些类型的数据并不直接与内置类型一致，比如低于秒级精度的时间戳；比如 IPv4 地址，人们常用 `VARCHAR(15)` 来存储，实际上它是 32 位无符号整数，小数点只是为了便于阅读，MySQL 提供 `INET_ATON()` 和 `INET_NTOA()` 在这两种表示方式间转换

## 4.2 schema 设计中的陷阱

### 太多的列

MySQL 的存储引擎 API 工作时需要在服务器层和存储引擎层间通过行缓冲格式拷贝数据，然后在服务器层将缓冲内容解码成各个列；从行缓冲中将编码过的列转换成行数据结构的操作代价是非常高的。MyISAM 的定长行结构与服务器层的行结构正好匹配，不需要转换；MyISAM 的变长行结构和 InnoDB 的行结构则总是需要转换，转换的代价依赖于列的数量，如果使用非常宽的表（数千个字段），但只有一小部分列会实际用到，则转换的代价非常高

### 太多的关联

“实体-属性-值”(EAV) 设计模式很糟糕，在 MySQL 下不能靠谱地工作，MySQL 限制了每个关联操作最多只能有 **61** 张表，但 EAV 数据库需要很多自关联；即使少于 61 张表，解析和优化查询的代价也是个问题，单个查询最好在 **12** 个表以内做关联

### 全能的枚举

防止过度使用枚举(ENUM)，比如不应该将纯数字，数量多且易改变的列设为 ENUM 类型；枚举类型的改变需要 ALTER TABLE，代价较大；可以存放整数类型并以其为外键关联到字典表来代替 ENUM

### 变相的枚举

枚举列(ENUM)存储一组定义值中的单个值，集合列(SET)则存储一组定义值中的一或多个值，容易导致混乱，当只存一个值时应该使用 ENUM 而不是 SET

### NULL

尽量避免用 NULL，可以用 0、空字符串或某个特殊值代替，但也不要走极端，该用的时候就用，不要为此把事情复杂化；  
MySQL 会在索引中存储 NULL 值，而 Oracle 不会

## 4.3 范式与反范式

### 范式的优缺点

优点：
* 范式化的更新操作通常比反范式化要快
* 当数据较好地范式化时，只有很少或没有重复数据，所以只需要修改更少数据
* 范式化的表通常更小，可以更好地放在内存里，执行操作会更快
* 很少有冗余数据意味着检索列表数据时更少需要 `DISTINCT` 或 `GROUP BY` 语句

缺点：通常需要很多关联，代价昂贵，还可能使一些索引策略无效（因范式化而拆开在不同表里的列，若在同一表中本可以属于同一索引）

### 反范式的优缺点

优点：不需要关联，对于大部分查询最差的情况--全表扫描，避免了随机 I/O（全表扫描一般是顺序 I/O），当数据比内存大时会比关联快很多；也可以使用更有效的索引策略

实际应用中一般混合使用范式与反范式

## 4.4 缓存表和汇总表

没有标准含义，这里**缓存表**表示存储可以比较简单地从其它表获取的数据（但获取速度较慢）的表；**汇总表**表示存储的是用 `GROUP BY` 语句聚合数据的表。

实时统计一般代价昂贵，因为需要扫描表中的大部分数据，或者查询语句只能在特定的索引上才能有效运行，但这些索引会影响 UPDATE 操作，可以每隔一小段时间进行一次统计，存入汇总表，最后统计汇总表中的数据；  

缓存表则对优化搜索和检索查询语句很有效，这些查询语句经常需要特殊的表和索引结构，跟普通 OLTP 操作用的表有所区别；缓存表可能只包含主表的部分列，甚至使用不同的存储引擎，比如主表用 InnoDB，缓存表用 MyISAM 则索引占用空间更小，并且可做全文搜索；

使用缓存表和汇总表时，必须决定是实时维护数据还是定期重建；定期重建可节省资源，还可保持表不会有很多碎片，有完全顺序组织的索引；  

当重建缓存表和汇总表期间，通常需要保证数据依然可用：创建一张结构一致的影子表，填充好数据后，再通过 RENAME TABLE 操作将真实表变为旧表，影子表变为真实表，这样还能保留上版本的数据，可随时回滚

### 物化视图

预先计算并且存储在磁盘上的视图，不像普通视图是虚拟的，这是实际占用空间进行物理存储的视图；很多数据库都有提供物化视图，但是 MySQL 没有，可以使用开源工具 Flexviews 来自己实现，它由这几部分组成：
* 变更数据抓取功能（CDC），可以读取服务器的二进制日志并解析相关行的变更
* 一系列可帮助创建和管理视图定义的存储过程
* 一些可应用变更到数据库中的物化视图的工具

Flexviews 通过提取对源表的修改，可以增量更新，不需要通过查询原始数据来更新视图：基于行的二进制日志包含行更新前后的镜像，不需要查找源表就能知道每行数据的新值和旧值，计算增量数据比从源表读取数据的效率高很多

### 计数器表

在需要计数的场合，如网站访问数，文章点击数等，如果在源表中添加一列作为计数器，在更新计数器时可能出现并发问题（比如更新或读取源表数据与更新计数器之间的锁互斥），所以应该用一张独立的表存储计数器，这样计数器表小且快，还可避免更新计数器时使源表的查询缓存失效；  

最简单的计数器表是每个计数器有一行数据，但是在高并发下不好，可以用多行数据来作为一个计数器，更新时随机更新其中一行，查询时用 SUM() 来统计所有行作为最终计数；  
如果需要每天分开计数，不必预先生成行，可以用 `ON DUPLICATE KEY UPDATE` 代替（有重复主键时更新否则插入）：
```sql
--主键为 (day, slot)
INSERT INTO daily_hit_counter(day, slot, cnt)
    VALUES (CURRENT_DATE, RAND() * 100, 1)
    ON DUPLICATE KEY UPDATE cnt = cnt + 1;
```

## 4.5 加快 ALTER TABLE 速度

大多情况下，MySQL 执行 `ALTER TABLE` 的方式是用新的结构创建一个空表，从旧表中查出所有数据插入新表，然后删除旧表，这非常耗时，特别是表很大且内存不足，有很多索引时；  
5.1 以后的版本包含一些类型的“在线”操作，在操作过程中不锁表 ? InnoDB 也支持通过排序来建索引，更快且索引布局更紧凑；  
大部分 `ALTER TABLE` 操作将使 MySQL 服务中断，以下技巧可以规避：
* 在另一台不提供服务的机器上执行 `ALTER TABLE`，然后和提供服务的主库切换
* 影子拷贝，创建一张新结构的新表，通过重命名和删表操作与源表交换
* 使用 Flexviews，利用其 CDC 工具执行无锁的表结构变更

ALTER TABLE 不一定会重建表，比如改变或删除一列的默认值，有几种方法：
* `MODIFY [COLUMN] col_name col_def [FIRST | AFTER col_name]`: 
    直接重新定义某列，改变列的位置，会重建表
* `ALTER [COLUMN] col_name {SET DEFAULT literal | DROP DEFAULT}`: 
    列的默认值存在表的 .frm 文件中，这个语句直接修改文件，不重建表
* `CHANGE [COLUMN] old_col_name new_col_name col_def [FIRST|AFTER col_name]`：
    比 MODIFY 增加了重命名的功能，其余一致

### 修改 .frm 文件

其它不需要重建表的操作：
* 移除一个列的 AUTO_INCREMENT 属性
* 增加、移除或更改 ENUM 和 SET 常量，如果移除的是已经有行数据使用其值的常量，查询会返回空字符串

修改 .frm 文件步骤：
1. 创建一张有相同结构的空表，并进行需要的修改（仅限上面两种）
2. 执行 `FLUSH TABLES WITH READ LOCK`，会关闭所有正在使用的表，并禁止任何表被打开
3. 交换 .frm 文件
4. 执行 `UNLOCK TABLE` 释放第 2 步的读锁
5. 删除辅助表

### 快速创建 MyISAM 索引

高效载入数据到 MyISAM 表：先禁用索引(`DISABLE KEYS`)，载入数据，再启用索引(`ENABLE KEYS`);  
构建索引的工作被延迟到数据完全载入后，这时可以通过排序来构建索引，更快且索引树碎片更少更紧凑；但是对**唯一索引**无效，MyISAM 会在内存构造唯一索引，且为载入的每一行检查唯一性，一旦索引大小超过有效内存大小，载入操作会越来越慢；  
InnoDB 有类似技巧，依赖于其快速在线索引创建功能：先删除索引非唯一索引，增加新列，最后重新创建索引；  

当已知**所有数据都有效且无需做唯一性检查**时（比如从备份载入数据）可用以下方法：
1. 用需要的结构创建一张表，不含索引
2. 载入数据到表中以构建 .MYD 文件
3. 创建相同结构的另一张空表，包含索引，会创建出所需的 .frm 和 .MYI 文件
4. 获取读锁并刷新表
5. 重命名第二张表的 .frm 和 .MYI 文件为第一张表的名字
6. 释放读锁
7. 使用 `REPAIR TABLE` 重建表的索引，会通过排序来构建所有索引，包括唯一索引

# 第 5 章 创建高性能的索引

## 5.1 索引基础

索引可以包含一个或多个列的值，如果包含多个列，那么列的顺序很重要，因为 MySQL 只能高效地利用索引的最左前缀列，索引对多个列的排序依据为定义索引时列的顺序

索引在存储引擎层实现，没有统一标准，不同存储引擎的索引的工作方式不同，支持的索引类型也不一定相同，即使索引类型相同，其底层实现也可能不同

### B-Tree 索引

大多数存储引擎都支持，但不一定用 B-Tree 结构来存储，比如 NDB 集群存储引擎用的是 T-Tree 结构，InnoDB 则是 B+Tree 结构；  
MyISAM 使用前缀压缩技术使得索引更小，InnoDB 则按照原数据格式存储；MyISAM 索引通过数据的物理位置引用被索引的行，InnoDB 则根据主键引用被索引的行；  

B-Tree 索引能加快访问数据的速度，存储引擎不再需要进行全表扫描来获取数据，而是从树的根节点向下查找，在叶节点找到所需数据的索引，其指针指向被索引的数据；  
B-Tree 对索引列是按顺序组织存储的，适合查找范围数据；  

B-Tree 索引适用于全键值、键值范围或键前缀查找（只适用于根据最左前缀的查找），对如下类型的查询有效：
* **全值匹配**：匹配索引中**所有的列**
* **匹配最左前缀**：只匹配索引的**第一列**
* **匹配列前缀**：匹配某一列的开头部分
* **匹配范围值**：匹配某一列的范围值
* **精确匹配某一列并范围匹配另一列**：范围匹配包括列前缀和范围值(LIKE, BETWEEN)
* **只访问索引的查询，即覆盖索引**
当 ORDER BY 字句满足上面几种类型时，索引也会生效

B-Tree 索引的限制：
* 必须从索引的第一列开始查找
* 不能跳过索引中的列，必须按照定义索引时的列顺序来查找（如果没有跳过列，只是没按顺序的话，一般会被查询优化器纠正）
* 如果查询中有某列的范围查询（列前缀或范围值），则其右边所有列都无法使用索引优化查找(在 WHERE 中使用了范围查询，ORDER BY 中的列也应用不了索引)

使用了索引查询，精确查询时，EXPLAIN 的 Type 列为 "ref"，范围查询则为 "range"；  

### 哈希索引

基于哈希表实现，只有精确匹配索引所有列的查询才有效；  
只有 Memory 引擎显式支持哈希索引，且是其默认索引类型，且支持非唯一哈希索引，如果多行的哈希值相同，则以链表方式存放多个记录指针到同一哈希条目中；（NDB 集群引擎支持唯一哈希索引，但作用特殊，不属于此书范围）   

哈希索引的限制：
* 只包含哈希值和行指针，不存储字段值，必须读取行，但访问内存中的行的速度很快，影响不大
* 索引不按索引值顺序存储，无法用于排序
* 不支持部分索引列匹配查找
* 只支持等值比较查询，不支持范围查询
* 哈希冲突很多时，必须遍历链表中的行指针，逐行比较来找出正确的行
* 哈希冲突很多时，一些索引维护操作的代价也很高，比如删除某一行时，必须遍历对应哈希值的链表中的行指针，删除对应指针，冲突越多，代价越大

InnoDB 有“自适应哈希索引”的功能，当其注意到某些索引值被使用很频繁是，会在内存中基于 B-Tree 索引智商在创建一个哈希索引，使 B-Tree 索引也具有哈希索引的一些优点，这是一个完全自动的、内部的行为，用户无法配置或控制，但可以关闭（innodb_adaptive_hash_index 开启/关闭，默认是开启）

#### 创建自定义哈希索引

在不支持哈希索引的存储引擎中自定义哈希索引，可以享受一些哈希索引的便利，如只需要很小的索引就能为超长的键建立索引；  
思路是增加一列存放另一个值很长的列的哈希值，对哈希列建立 B-Tree 索引，维护哈希值可以用触发器实现；  
使用 `CRC32()` 生成哈希值(32 位整数)，不要用 `SHA1()` 或 `MD5()`，因为它们计算出来的值是很长的字符串；
若产生大量哈希冲突，可考虑自己实现 64 位哈希函数，或者用 `MD5()` 返回值的一部分作为哈希值；为避免哈希冲突，查询时除了对比哈希值还需对比原值

### 空间数据索引 R-Tree

MyISAM 支持，可以用作地理数据存储，无需前缀查询，会从所有维度索引数据；必须用 GIS 相关函数如 MBRCONTAINS() 等来维护数据，但 MySQL 的 GIS 支持并不完善

### 全文索引

不是直接比较索引中的值，而是查找文本中的关键词，类似于搜索引擎，同一列上于 B-Tree 索引不冲突，适用于 MATCH AGAINST 操作，而不是 WHERE

## 5.2 索引的优点

三大优点：
* 大大减少服务器需要扫描的数据量
* 可帮助服务器避免排序和临时表
* 可将随机 I/O 变为顺序 I/O

* 索引最好吗？
    对于很小的表，一般简单的全表扫描更高效；对于中大型表，索引很有效；对于特大型的表，建立和使用索引的代价也随之增长，需要可以直接区分出查询需要的一组数据的技术，比如分区技术（7章）；如果表很多，可以建一个元数据信息表，存放需要用到的特性，比如哪个用户的信息存储在哪个表中，对于 TB 级别的数据一般会用块级别元数据技术代替索引

## 5.3 高性能的索引策略

### 独立的列

查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引！

### 前缀索引和索引选择性

如果索引很长的字符串，索引会很大很慢，除了模拟哈希索引还可以前缀索引；  
前缀索引可节约索引空间，但也降低了索引的选择性；

* 索引选择性
    不重复的索引值（基数）和数据表的记录总数（#T）的比值（1/#T ~ 1）；  
    选择性越高则查询效率越高，唯一索引的选择性是 1

诀窍是选用适当长度的前缀，是前缀的基数接近于完整列的基数；  

缺点：无法用前缀索引做 ORDER BY 和 GROUP BY，也无法做覆盖扫描

创建前缀索引：`ALTER TABLE table ADD KEY(index(num));`

* 后缀索引也有用途，比如找到某个域名的所有电子邮件地址，MySQL 原生不支持反向索引，但可以把字符串反转后存储，并基于此建立前缀索引，用触发器维护（为什么不直接将后缀单独一列存放并建立普通索引呢？）

### 多列索引

对于多条件的查询语句，在多个列上建立单列索引大部分情况并不能提高查询性能；  
不过 5.0 版本后引入了**索引合并**策略，一定程度上可以用表上多个单列索引来定位指定的行；  
老版本上多列的 OR 条件会变成了全表扫描，5.0 以后版本则会同时使用多个单列索引进行扫描，然后将结果合并（OR 取并集，AND 取交集），具体可看 EXPAIN 中的 Extra 列

索引和并策略是一种优化，但也说明了表上的索引建得很糟糕：
* 当对多个索引取交集时（AND），意味着需要一个包含所有相关列的多列索引
* 当对多个索引取并集时（OR），通常会耗费大量 CPU 和内存资源在算法的缓存、排序和合并操作上，特别是当其中有些索引的选择性不高，需要合并扫描大量数据时
* ！优化器不会把这些消耗计算到“查询成本”（cost）中，它只关心随机页面读取，这使查询成本被低估，导致执行计划还不如直接全表扫描，消耗更多资源的同时还可能影响查询的并发性

可以通过参数 `optimizer_switch` 关闭索引合并功能，也可以用 `IGNORE INDEX` 让优化器忽略某些索引

### 合适的索引列顺序

索引列的顺序需要与 ORDER, GROUP, DISTINC 等子句的顺序相同才能起作用，当没有这些子句时，可将选择性高的列放在前面，但是也要考虑运行频率很高的查询语句的情况

### 聚簇索引

一种数据存储方式（不是单独的索引类型），InnoDB 中的实现为在同一个结构中保存了 B-Tree 索引和数据行；  

**InnoDB**：当表有聚簇索引时，其数据行存放在索引的**叶子页**中，因此每个表只能有一个聚簇索引（覆盖索引可以模拟多个聚簇索引的情况），且索引列只能是**主键**，除非没有定义主键，则会选择一个**唯一非空索引**代替，还没有则隐式定义一个主键代替；只聚集在同一页中的记录，包含相邻键值的页可能会相距甚远

优点：
* 将相关数据保存在一起，比如根据用户 ID 聚集，只需从磁盘读取少数的数据页就能获取某个用户的所有数据，否则每条数据都可能导致一次磁盘 I/O
* 数据访问更快，将索引和数据行保存在同一个 B-Tree 叶子页中，直接获取到数据，比非聚簇索引更快
* 使用覆盖索引扫描的查询可以直接使用页节点中的主键值 ?

缺点：
* 虽然最大限度地提高了 I/O 密集型应用地性能，但如果数据全部放在内存中，则访问顺序就没那么重要了，也即聚簇索引没什么优势了
* 插入速度严重依赖于插入顺序，按主键顺序插入最快，否则较慢，且数据全部加载完后最好用 `OPTIMIZE TABLE` 命令重新组织一下表
* 更新索引列地代价很高，因为会强制 InnoDB 将每个被更新地行移动到新位置
* 插入新行或主键被更新导致需要移动行时，可能面临**页分裂**的问题：若要插入的页已满，则存储引擎将该页分裂成两页再存储该行，页分裂会导致表占用更多磁盘空间
  * 当页中的内容达到页的最大填充因子时（InnoDB 默认为页大小的 15/16，留出部分空间用于以后修改），视为页已满，就不能插入新行；
  * 新增时若为顺序插入，比如主键是自增列，不会出现页分裂，而是在页满时，写入到新的页
* 可能导致全表扫描变慢，尤其是行比较稀疏，或由于页分裂而导致数据存储不连续时
* 二级索引（非聚簇索引）可能较大，因为其叶子节点也包含了引用行的主键列
* 二级索引访问需要**两次**索引查找：二级索引的叶子节点保存的“行指针”并不指向行的物理位置，而只是行的主键值，还需要去聚簇索引查找对应行，需要两次 B-Tree 查找；对应 InnoDB，自适应哈希索引能减少这样的重复操作

另外非聚簇索引也不一定一次索引查询就找到行 ?，当行更新时可能无法存储在原位置，会导致表中出现行的碎片化或移动行并在原位置保存**向前指针**，这会需要更多工作

#### 数据分布

##### MyISAM

MyISAM 不支持聚簇索引，其数据行按插入顺序存储在磁盘上；若行是定长的，则会有一个从 0 开始递增的行号，这样就可以从表的开头跳过一定字节找到需要的行（变长行使用别的策略）；
所有索引都是一样，在叶节点上，按列值排序，“行指针”即是对应的行号，主键索引只是一个名为 PRIMARY 的唯一非空索引

##### InnoDB

聚簇索引的叶节点上保存着索引列（一般是主键），事务 ID，用于事务和 MVCC 的回滚指针，剩余的列；如果主键是列前缀索引，也会包含完整的主键列和其他列；聚簇索引即是完整的表；  
二级索引中，叶节点存储的“行指针”为主键值（聚簇索引列的值），这会占用更多空间，但减少了当出现行移动或数据页分裂时二级索引的维护工作，不用去更新二级索引中的“行指针”

#### 顺序与随机主键

如果某表没有什么数据需要聚集，可以定义一个代理键作为主键，其数据与应用无关，最简单的就是用 AUTO_INCREMENT 自增列，可以保证数据行按顺序写入，根据主键做关联操作时性能很好；  
避免随机的（不连续且值的分布范围很大）聚簇索引，特别是对应 I/O 密集型应用；比如 UUID 作为聚集索引会很糟，使得插入完全随机，数据没有任何聚集特性；   

自增列的主键新增插入时为顺序插入，只需插入到聚簇索引的最后即可，如果当前页已达到最大填充因子，则插入到新页；  
但 UUID 的主键则不是顺序插入，需要很多额外工作：
* 写入的目标页可能已经刷到磁盘上并从缓存中移除，或还未加载到缓存中，InnoDB 在插入前要先找到并从磁盘读取目标页到内存中，将导致大量的随机 I/O
* 因为写入是乱序的，InnoDB 会频繁地做页分裂操作，以便为新的行分配空间，页分裂导致移动大量数据，一次插入至少修改三个页
* 由于频繁的页分裂，页会变得稀疏并被不规则地填充，产生碎片

顺序主键缺点：
在高并发下可能造成明显的争用，可配置 innodb_autonic_lock_mode 来改善 ?

大量数据插入后需要用 `OPTIMIZE TABLE` 重建表并优化页的填充

### 覆盖索引

设计索引除了考虑 WHERE 条件之外，还要考虑整个查询语句；如果使用索引直接获取到所需数据，就不需要再读取数据行了；  
如果一个索引包含所有需要查询的字段的值，则为**覆盖索引**，可以极大提高性能，只扫描索引，无需回表；  

优点：
* 索引条目通常远小于数据行大小，如果只需读取索引，会极大减少数据访问量，对缓存的负载很重要，因为这时响应时间大部分花在数据拷贝上；对于 I/O 密集型应用也有帮助，因为索引比数据小，更容易全部放入内存（特别是 MyISAM，能压缩索引）
* 因为索引按列值顺序存储（至少单个页内这样），所以 I/O 密集型的范围查询会比随机从磁盘读取每一行数据的 I/O 少得多
* 一些存储引擎如 MyISAM 在内存中只缓存索引，数据依赖于操作系统来缓存，要访问数据需要一次系统调用，会导致严重的性能问题尤其是这些系统调用占了数据访问中最大开销的场景
* 由于聚簇索引，覆盖索引对 InnoDB 很有用，其二级索引在叶节点保存了主键，如果二级索引能覆盖查询，可避免对主键索引的二次查询

覆盖索引必须存储索引列的值，哈希索引、空间索引和全文索引等都不存，MySQL 中只能用 B-Tree 索引；  

当发起索引覆盖查询时，在 EXPLAIN 的 Extra 列显示 **Using index**；  

对于二级索引，由于存有主键值，因此也可对主键值进行覆盖查询；  

对于 WHERE 条件为索引覆盖，但 SELECT 的字段无法被索引覆盖的查询，可以考虑用子查询优化，将 WHERE 条件移到子查询中，用覆盖查询查出索引中的字段，再与原表连接，查出需要的字段，称为**延迟关联**，比如：
```SQL
SELECT * FROM users WHERE id < 10;
--优化后
SELECT * FROM users JOIN (SELECT id FROM users WHERE id < 10) t1 ON users.id = t1.id;
```

### 使用索引扫描进行排序

MySQL 有两种方式生成有序结果：通过排序操作，或按索引顺序扫描；  
若 EXPLAIN 的 Type 列为 "index"，就是进行了索引扫描，若此时 Extra 列不含 "Using filesort"，即是按索引顺序扫描进行了排序；  
扫描索引很快，只需从一条索引记录移动到紧接着的下一条，但若不是覆盖索引，每扫描一条索引记录还要回表查询一次定义行，这基本都是随机 I/O，因此按索引顺序读取数据的速度通常比顺序地全表扫描慢，尤其在 I/O 密集型的工作负载时；  

设计索引时，应尽量考虑既满足排序，又用于查找行；  
只有当索引的列顺序与 ORDER BY 子句顺序完全一致，且所有列的排序方向（正序或倒序）都一样时，才能用索引来排序，但如果在 WHERE 子句中为索引前几列指定常量，ORDER BY 子句可以直接从后几列开始排；  
如果查询关联多张表，只有当 ORDER BY 字句的字段全为第一个表时，才能用索引来排序；  
若在 WHERE 条件中使用索引进行范围查询，则 ORDER BY 无法使用索引优化

* 仅按索引扫描，而没用 ORDER BY 的情况：
  * WHERE 语句中的索引列没有遵循最左前缀原则，跳过了最前的一些列，若为**索引覆盖**，这时虽然无法使用索引查询（Type: ref），但还是会用到索引扫描（Type: index）；
  * 索引覆盖时，使用范围条件，优先使用索引扫描（Type: index），而不是范围查询（Type: range）

### 压缩索引（前缀压缩）

MyISAM 使用前缀压缩来减少索引大小，默认只压缩字符串，可以通过参数设置对整数做压缩；  
压缩每个索引块的方法是：先完全保存索引块第一个值，然后将其它值与第一个值比较，得到相同前缀的字节数和剩余的不同后缀部分，存储起来即可，比如第一个值 "perform"，第二个值 "performance"，第二个压缩后类似于 "7,ance" 的形式；  
MyISAM 对行指针也采用类似压缩方式；  

压缩块占用空间小，但某些操作更慢，查找时无法在索引块使用二分查找，而只能从头扫描；正序扫描还好，倒序扫描则较差，在块中查找某一行的操作平均需要扫描半个索引块；  

对于 CPU 密集型应用，因为扫描需要随机查找，压缩索引使得索引查找要慢上好几倍，倒序扫描还要更慢，在 I/O 密集型应用中，由于占用空间小，对某些查询很有用；  

在 CREATE TABLE 语句中指定 PACK_KEYS 参数来控制索引压缩方式

### 冗余和重复索引

#### 重复索引

MySQL 允许在相同列上创建多个索引，相同列上按相同顺序创建的相同类型的索引为**重复索引**，MySQL 需要单独维护重复的列，且优化器在优化查询时也需逐个进行考虑，会影响性能；  
* MySQL 的唯一限制和主键限制都是通过索引实现的，因此当把一列设为主键后，没必要在将它设为唯一列或添加索引，会导致重复索引

#### 冗余索引

冗余索引是指，对已有多列索引的**最左前缀列**建立索引，比如已有索引 (A, B)，再创建索引 (A) 就是冗余索引，因为索引 (A, B) 完全可以当做索引 (A) 来使用；  
因为 InnoDB 中二级索引也包含了主键，所以类似索引 (A, id) 也是冗余的；对于索引 (A)，在像 `WHERE A = 5 ORDER BY id` 这样的查询中很有效，但如果将其扩展为 (A, B)，即相等于 (A, B, id)，则在类似前面的查询中，该索引不再有效，所以扩展索引时也要留意；    

大部分情况不需要冗余索引，但有时扩展已有索引会使其变得太大，影响其他使用该索引的查询的性能，这就需要新建索引；当然，索引越多，增加/修改/删除操作越慢

### 未使用索引

永远用不到的索引应该删除，浪费资源，可以在 Percona Server 或 Maira DB 中先打开 userstates 服务器变量（默认关闭），然后让服务器正常运行一段时间，再通过查询 INFORMATION_SCHEMA.INDEX_STATISTICS 就能查到每个索引的使用频率；或者用 Percona Toolkit 中的 pt-index-usage 工具，可以读取查询日志，并对日志中每条查询进行 EXPLAIN 操作，打印出关于索引和查询的报告

* 有些索引用于唯一约束，虽然不会在查询中被使用，但保证了数据不会重复，要注意区分

### 索引和锁

索引可让查询锁定更少的行，从而减少锁定行时的开销，避免因锁定超过需要的行而增加锁争用并减少并发性；  
InnoDB 只在访问行时才对其加锁，而索引能减少访问的行数，从而减少锁的数量，但只有当 InnoDB 在存储引擎层能过滤掉不需要的行时才有效；  
如果索引无法过滤掉无效行，那么在 InnoDB 检索到数据并返回给服务器层后，服务器才能应用 WHERE 语句（5.6 版本后可能改善），这时已经无法避免锁定行了，InnoDB 已经锁定这些行，5.1 版本后可在服务器过滤掉行后释放锁，之前只能在事务提交后释放锁

* 给查询加锁：`SELECT ... FOR UPDATE;`，会阻塞 UPDATE 操作和其它 SELECT FOR UPDATE 操作

即使用了索引，InnoDB 也可能锁住一些不需要的数据（一些 WHERE 条件需要在服务器端进行过滤），如果不用索引则更糟，会做**全表扫描并锁住所有行**

InnoDB 在二级索引上使用共享锁（读锁），但访问主键索引需要排它锁（写锁），这消除了使用覆盖索引的可能性，并且使得 SELECT FOR UPDATE 比 LOCK IN SHARE MODE 或非锁定查询慢很多 ??

## 5.4 索引案列学习

一些技巧：
* 当一个列的值只有很少种情况且作为索引前列时，比如性别，可以用 `sex IN ('m','f')`，来避免过滤性别并满足最左前缀原则，使查询能用索引优化；此时，EXPLAIN 的 Type 列为 "Range"，但这跟范围查询不同，其后的索引列仍能被使用
* 经常要进行范围查询的列尽可能放在索引最后面
* 若需要两个列同时做范围查询，且使用索引，可考虑将其中一个值域可列举的列的条件转换为 `IN (...)` 的形式

## 5.5 维护索引和表

维护索引和表有三个主要目的：找到并修复损坏的表，维护准确的索引统计信息，减少碎片

### 找到并修复损坏的表

对于 MyISAM，表损坏通常是系统崩溃导致的，其它引擎也会由于硬件问题，MySQL 本身的缺陷或者操作系统的问题导致索引损坏；  
损坏的索引会导致查询返回错误结果或主键冲突等问题，严重时还会导致数据库崩溃；  

CHECK TABLE 命令可检查是否发生表损坏，能找出大多数表和索引的错误；  
REPAIR TABLE 命令可修复损坏的表，如果存储引擎不支持，可用一个不做任何操作的 ALTER TABLE 命令来重建表，比如对于 InnoDB 表：
`ALTER TABLE table_name ENGINE=INNODB`  
或者将数据导出一份，再重新导入；或者使用一些相关的工具等；  
但如果损坏的不是索引，而是系统区域，或者是表的“行数据”区域，上面的方法就没用了，只能从备份中恢复，或尝试修复损坏的数据文件；  

InnoDB 一般不会损坏，其设计确保了这点；如果损坏，一般是数据库硬件问题（如内存或磁盘），或者有人在外部误操作了数据文件，或是 InnoDB 本身的弊端；可设置 innodb_force_recovery 参数进入 InnoDB 的强制恢复模式来修复数据

### 更新索引统计信息

MySQL 的查询优化器通过两个 API 来了解存储引擎的索引值的分布信息，以决定如何使用索引：
* records_in_range()：传入两个边界值，获取在这范围内大概有多少条记录，一些引擎返回精确值（MyISAM），一些则是估算值（InnoDB）
* info()：返回各种类型的数据，包括索引的基数

如果存储器向优化器提供的扫描行数信息不准确，或执行计划太复杂以致无法准确获取各个阶段匹配的行数，那么优化器会用索引统计信息来估算扫描行数；如果表没有统计信息，或不准确，优化器就可能做出错误决定，用 ANALYZE TABLE 命令重新生成统计信息来解决这个问题；  
不同引擎实现索引统计信息的方式不同，所以需要 ANALYZE TABLE 的频率、每次运行的成本也不同：
* Memory 不存储索引统计信息
* MyISAM 将索引统计信息存储在磁盘，ANALYZE TABLE 需要进行一次全索引扫描来计算索引技术，整个过程锁表
* InnoDB 不在磁盘存储索引统计信息，通过随机的索引访问进行评估并存储在内存中

使用 `SHOW INDEX FROM table_name` 命令查看索引信息，其中 Cardinality 列为索引的基数；或者从 `INFORMATION_SCHEMA.STATISTIC` 表查询，但若服务器上的库表非常多，这样获取元数据的速度可能非常慢；  

InnoDB 通过抽样的方式计算统计信息：先随机读取少量索引页面，然后以此为样本计算索引的统计信息，在老版本中，样本页面数为 8，新版本可通过参数 `innodb_stats_sample_pages` 来设置样本页数量（5.6.3 后是 `innodb_stats_transient_sample_pages`），值越大，生成的索引信息越准确；  
InnoDB 在表首次打开，或执行 ANALYZE TABLE，或表的大小发生巨大变化（大小变化超过十六分之一或新插入 20 亿行）时计算索引统计信息；  
还有在打开某些 `INFORMATION_SCHEMA` 表，或使用 `SHOW TABLE STATUS` 和 `SHOW INDEX`，或在 MySQL 客户端开启自动补全功能时都会触发更新索引统计信息，当有大量数据是占用很多性能资源，可以关闭 `innodb_stats_on_metadata` 参数来避免；不过关闭索引统计信息的自动更新后，必须周期性的使用 ANALYZE TABLE 来手动更新！

### 减少索引和数据的碎片

B-Tree 索引可能碎片化，会以很差或无序的方式存储在磁盘上，会降低查询效率；  
B-Tree 需要随机磁盘访问才能定位到叶子页，所以随机访问不可避免，但若叶子页在物理上分布是顺序且紧密的，查询性能就会很好，否则，对于范围查询、**索引覆盖扫描**等操作来说，速度会降低很多；  

表的数据存储也会碎片化，有三种类型：
* **行碎片**：数据行被存储在多个地方的多个片段中，即使查询只从索引中访问一行记录，行碎片也会导致性能下降
* **行间碎片**：指逻辑顺序上的页，或行在磁盘上不是顺序存储的；对诸如全部扫描和聚簇索引扫描之类的操作影响很大，因为这些操作原本能从磁盘上顺序存储的数据中获益
* **剩余空间碎片**：指数据页中有大量空余空间，会导致服务器读取大量不需要的数据

MyISAM 这三种碎片都可能发生，InnoDB 不会出现短小的行碎片，它会移动短小的行并重写一个片段中；  

执行 `OPTIMIZE TABLE` 或导出再导入的方式可重新整理数据；MyISAM 可通过排序算法重建索引的方式消除碎片；InnoDB 有“在线”添加和删除索引的功能，可先删除再重新创建索引的方式来消除锁品的碎片化；  

对于不支持 `OPTIMIZE TABLE` 的引擎，可通过一个不做任何操作的 ALTER TABLE 操作来重建表，比如：
`ALTER TABLE table_name ENGINE=INNODB`  
对于开启了 `expand_fast_index_creation` 参数的 Percona Server，这样重建表会同时消除表和索引的碎片化，标准的 MySQL 则只会消除表（实际是聚簇索引）的碎片化；可用先删除所有索引，再重建表，最后重建索引的方式模拟这个功能

# 第 6 章 查询性能优化

## 6.2 优化数据访问

查询性能低下的最基本原因是访问的数据太多，大部分性能低下的查询可以通过减少访问的数据量的方式进行优化；通过以下两个步骤进行分析：
* 确认应用程序是否在检索大量超过需要的数据，一般是访问了太多的行，也可能是太多的列
* 确认服务器层是否在分析大量超过需要的数据行

### 请求过量数据

有些查询会请求超过实际需要的数据，然后多余的数据被应用程序舍弃，给 MySQL 服务器带来了额外的负担，增加网络开销，消耗应用服务器的 CPU 和内存资源

典型案例：
* **查询不需要的记录**：查询过量数据，只获取一小部分，然后关闭结果集，误以为数据库只会查询出这一小部分数据，这是错误的，数据库会查询全部数据到结果集中，之后是在应用程序中过滤，应该用 LIMIT 等方式限制查询数据的量
* **多表关联是返回全部列**
* **总是取出全部列**：即 `SELECT * FROM ...`，会让优化器无法完成索引覆盖扫描这类优化，为服务器带来额外 I/O、内存和 CPU 消耗；但可以简化开发，提高了相同代码片段的复用性，如果应用程序使用了某种缓存机制，可能还有好处；要仔细斟酌
* **重复查询相同数据**：将数据缓存起来

### 扫描额外记录

MySQL 最简单的衡量查询开销的三个指标：
**响应时间，扫描行数，返回行数**  
这三个指标会记录到 MySQL 的慢日志中，检查慢日志记录是找出扫描行数过多的查询的好办法

#### 响应时间

**服务时间和排队时间**之和：
服务时间指数据库处理这个查询真正花的时间；排队时间指服务器因等待某些资源而没有真正执行查询的时间--等待 I/O 操作，锁等

#### 扫描行数和返回行数

理想情况下扫描行数和返回行数应该相等，但实际中扫描行数一般大于返回行数，此外还要注意，较短的行访问速度更快，内存中的行也比磁盘中的行访问速度更快

#### 扫描行数和访问类型

MySQL 有多种访问方式可以查找并返回一行结果，有的方式需要扫描多行才能返回一行，有的无需扫描就能返回结果；  
EXPLAIN 的 Type 列反映了访问类型；  
访问类型速度由慢到快，扫描行数由大到小排列为：  
**全表扫描-ALL，索引扫描-index，范围索引-range，精确索引-ref，唯一索引-eq_ref，常数引用-const** 等

当查询很少行却扫描了大量数据时，可以查询下列优化技巧：
* 使用索引覆盖扫描，存储引擎无需回表查询
* 改变库表结构，例如使用单独的汇总表
* 重写查询，让优化器能以更优的方式执行此查询

##### WHERE 条件

MySQL 一般以三种方式应用 WHERE 条件，由好到坏依次是：
* 在索引中使用 WHERE 条件来过滤不匹配记录，在存储引擎层完成
* 使用索引覆盖扫描（Extra: Using index）来返回记录，直接从索引中过滤不需要的记录并返回命中结果，在服务器层完成，但无需回表查询记录
* 先从数据表返回数据，然后过滤不满足条件的记录（Extra: Using Where），在服务器层完成

## 6.3 重构查询的方式

优化查询时，可以将查询转换写法使其以更快的速度返回一样的结果，也可以修改应用程序代码，并以另一种方式查询，达到同样目的

### 一个复杂查询还是多个简单查询

MySQL 从设计上让连接和断开连接都很轻量级，在返回一个小的查询结果方面很高效，加上现在的网络带宽和延迟，运行多个小查询不是大问题；  
但相比 MySQL 内部扫描内存的速度，响应数据到客户端的速度还是慢了许多，尽可能少的查询还是更好，但有时将一个大查询分解成多个小查询也很有必要，需要权衡利弊

### 切分查询

有时会将一个查询分为多次查询，每次查询的功能都一样，但只返回一部分结果；   
比如批量删除旧数据，如果一次性删除大量数据，可能导致锁住很多数据、沾满整个事务日志、耗尽系统资源、阻塞很多小而重要的查询，可以使用 LIMIT 将其切分，每次只删除一小部分数据，间隔一定时间执行，分散压力，减少锁的持有时间，降低影响

### 分解关联查询

关联查询可分解为对每个表进行一次单表查询，然后将结果在应用程序中进行关联，优点：
* 让缓存效率更高，许多应用程序可以方便地缓存单表查询的结果对象；而对于 MySQL 的查询缓存来说，如果关联的某个表发生变化，则无法使用查询缓存了，而分解后，若某个表很少改变，则该表的查询缓存就能被重复利用
* 分解后，执行单个查询可减少锁的竞争
* 在应用层做关联，更容易对数据库进行拆分，做到高性能和可扩展
* 查询效率可能有所提升
* 减少冗余记录的查询，在应用层做关联，则每条记录只需查询一次；而在数据库做关联查询，可能需要重复访问一部分数据，这样看，还可减少网络和内存消耗
* 相当于在应用层实现哈希关联，而不是 MySQL 的嵌套循环关联，某些场景中性能高很多

分解关联查询时，可将左表查询出来的结果放在 `IN (...)` 中，代替关联条件过滤右表数据

## 6.4 查询执行基础

步骤：
1. 客户端发送一条查询给服务器
2. 服务器先检查查询缓存，若命中缓存，则立刻返回缓存中的结果，否则下一步
3. 服务器进行 SQL 解析、预处理，再由优化器生成对应执行计划
   *  SQL 语句 --解析器--> 解析树 --预处理器--> 解析树 --优化器--> 执行计划
4. 服务器的查询执行引擎根据优化器生成的执行计划，调用存储引擎的 API 来执行查询
5. 返回结果给客户端

### MySQL 客户端/服务器通信协议

MySQL 客户端/服务器的通信协议是**半双工**的，即任一时刻，只能由一端向另一端发送数据，而不能双方同时发送，所以，无法也无需将一个消息切成小块独立发送；  
这使通信简单快速，但无法进行流量控制，一旦一端开始发送消息，另一端要接收完整个消息才能响应；  

客户端用一个单独的数据包将查询传给服务器，查询语句的最大长度由 `max_allowed_packet` 决定；  
服务器响应给客户端的数据通常很多，由多个数据包组成，当服务器开始响应客户端请求时，客户端必须完整接收返回结果，不能只接收前面几条数据就要求停止传输！  

多数连接 MySQL 的库函数可以获得全部结果集并缓存在内存里，还可逐行获取需要的数据，默认是前者，MySQL 通常需要等所有数据全发送给客户端才能释放这条查询占用的资源，所以前者可减少服务器压力，早点释放资源； ?  
当使用多数连接 MySQL 的库函数获取数据时，是从这个库函数的缓存获取数据；但当返回一个很大的结果集时，库函数会花很多时间和内存来存储所有结果集，这时可以不使用缓存，但在数据交互过程中，该查询会一直占用服务器资源

#### 查询状态

一个连接或者说一个线程，任何时刻都有一个状态，`SH0W FULL PROCESSLIST` 命令的 Command 列既是当前状态

* **Sleep**：线程正在等待客户端发送新的请求
* **Query**：线程正在执行查询或将结果发送给客户端
* **Locked**：在服务器层，线程正在等待表锁，在存储引擎级别实现的锁，如 InnoDB 的行锁，并不会体现在线程状态中
* **Analyzing and statistics**：线程正在收集存储引擎的统计信息，并生成查询的执行计划
* **Copying to tmp table [on disk]**：线程正在执行查询，并将结果集都复制到一个临时表中，一般是在做 GROUP BY，或是文件排序操作，或是 UNION 操作，如果后面带 **on disk**，表示正将一个内存临时表放到磁盘上
* **Sorting result**：线程正在对结果集进行排序
* **Sending data**：线程可能在多个状态间传送数据，或正在生成结果集，或在向客户端返回数据

### 查询缓存 Query Cache

解析查询语句前，若查询缓存是打开的，会优先检查这个查询是否命中查询缓存中的数据，通过一个对大小写敏感的哈希查找实现，即使只有一个字节不同，也无法命中缓存；  
若命中缓存，返回结果前会检查用户权限（缓存中已存放当前查询需要访问的表信息）

### 查询优化处理

包括 解析 SQL、预处理、优化执行计划

#### 语法解析器和预处理

首先，通过关键字解析 SQL 语句，并生成解析树。解析器将使用 MySQL 语法规则验证和解析查询，例如关键字及其顺序是否正确，引号是否匹配等；  
预处理器根据一些 MySQL 规则进一步检查解析树是否合法，例如数据表和列是否存在，名字和别名是否有歧义等；  
然后预处理器会验证权限

#### 查询优化器

优化器将合法的语法树转化为最优的执行计划；  
MySQL 使用基于成本的优化器，尝试预测一个查询使用某种执行计划时的成本，并选择其中成本最小的一个；  
最初，成本最小单位是随机读取一个 4K 数据页的成本，后来成本计算公式变得更复杂，并引入一些因子来估算某些操作的代价，如执行一次 WHERE 条件比较的成本；  
可通过查询当前会话的 `Last_query_cost` 值来得知计算出的当前查询的成本（单位是数据页），这是根据一系列统计信息计算得来的：每个表或索引的页面个数、索引的基数、索引和数据行的长度、索引分布情况；优化器评估成本时不考虑任何层面的缓存，它假设读取任何数据都需要一次磁盘 I/O；  

##### 错误选择计划

可能导致优化器选择错误执行计划的原因：
* 统计信息不准确，依赖存储引擎提供的统计信息来评估成本，但有的引擎提供的信息偏差大，例如 InnoDB 因为其 MVCC 架构，并不能维护一个数据表的行数的精确统计信息
* 执行计划中的成本估算不等同于实际执行成本，例如有时某个执行计划虽然需要读取更多页面，但这些页面都是顺序读或已存在内存中，则其成本将很小
* MySQL 的最优可能和人想的最优不一样，我们希望执行计划尽可能短，而 MySQL 只是基于其成本模型选择最优计划，可能不是最快的
* 从不考虑其它并发执行的查询
* 并不总是基于成本的优化，也会基于一些固定规则，例如，若存在全文搜索的 `MATCH()` 字句，则存在全文索引就用全文索引，但有时用别的索引和 WHERE 条件可比这种方式更快
* 不考虑不受其控制的操作的成本，例如执行存储过程或用户自定义函数的成本
* 优化器有时无法估算所有可能的执行计划，可能错过最优计划

##### 优化策略

优化策略简单分为两种：静态优化、动态优化；  
* **静态优化**可直接对解析树进行分析，并完成优化，不依赖于特别的数值，第一次完成后就一直有效，即使使用不同参数重复执行查询也不会变，可以说是“编译时优化”，例如通过简单的代数变换将 WHERE 条件转换为另一种等价形式；  
* **动态优化**与查询上下文及很多其它因素有关，例如 WHERE 条件中的取值、索引中条目对应的数据行数等，需要在每次查询时重新评估，有时甚至在查询的执行过程中也会重新优化，可以说是“运行时优化”
  * 在关联操作中，范围检查的执行计划会针对每一行重新评估索引，此时 EXPLAIN 的 Extra 列含有 `range checked for each record`，该计划还会增加 `select_full_range_join` 这个服务器变量的值

##### 优化类型

* **重新定义关联表的顺序**
* **将外连接转化为内连接**：并不是所有 OUTER JOIN 语句都必须以外连接的方式执行，诸多因素，例如 WHERE 条件、库表结构都可能让外连接等价于一个内连接，优化器能识别这点并重写查询让其可以调整关联顺序
* **使用等价变换规则**：使用一些等价变换来简化并规范表达式，合并和减少一些比较，移除一些恒成立和恒不成立的判断
* **优化 COUNT()、MIN() 和 MAX()**：索引和列是否可为空通常可帮助优化器优化这类表达式，例如一列的最小值，就是其对应 B-Tree 索引的最左端的记录，优化器会将这个表达式作为一个常数来对待；优化后，EXPLAIN 的 Extra 列含有 `Select tables optimized away`，表示优化器已从执行计划移除了该表，并以一个常数取代
* **预估并转化为常数表达式**：当优化器检测到一个表达式可转化为常数时，就会一直把它作为常数处理，例如在查询中不变的自定义变量，数学表达式等；有时一个查询也能转化为一个常数
* **覆盖索引扫描**
* **子查询优化**：某些情况可将子查询转换为效率更高的形式，减少多个查询多次访问数据
* **提前终止查询**：当发现已满足查询需求时，总能立刻终止查询，例如 LIMIT 子句，发现不成立条件（如查询负值 id ）等
* **等值传播**：如果两列的值通过等式关联，优化器能把其中一列的 WHERE 条件传递到另一列上
* **列表 IN() 的比较**：很多数据库中，`IN()` 完全等同于多个 OR 条件子句，复杂度为 O(n)；但 MySQL 不同，将 `IN()` 列表中的数据先排序，再用二分查找方式判断，复杂度为 O(log n)

#### 数据和索引的统计信息

统计信息有存储引擎实现，不同引擎可能存储不同的统计信息，某些引擎，如 Archive，则根本没有存储统计信息；  
服务器层没有统计信息，查询优化器在生成执行计划是，需要向存储引擎获取相应统计信息，包括：每个表或索引有多少页面、每个表的每个索引的基数、数据行和索引长度、索引的分布信息等

#### 如何执行关联查询

MySQL 认为任何一个查询都是一次关联(join)！
执行策略：对任何关联都执行嵌套循环关联操作，即先在一个表中循环取出单条数据，然后再嵌套循环到下一个表中寻找匹配行，直到找到所有表中匹配的行为止，然后根据各个表匹配的行，返回查询中需要的列；  
对于子查询也是一样，先执行子查询并将其结果放在临时表中，将临时表当做普通表对待（MySQL 的临时表没有任何索引！），执行 UNION 查询也使用类似临时表；右外连接则会被改写成等价左外连接，不过 5.6 版本后引入了更复杂的执行计划 ?

不过，不是所有查询都可以转换成嵌套循环关联操作，例如全外连接就无法通过嵌套循环和回溯的方式完成，这时当发现关联表中没有任何匹配行时，则可能是因为关联恰好从一个没有任何匹配的表开始，可能因此 MySQL 不支持全外连接；还有些场景，虽然可转换成嵌套循环，但效率很差

#### 执行计划

和很多其它关系数据库不同，MySQL 不会生成查询字节码来执行查询，而是生成查询的一颗指令树，然后通过存储引擎执行完这可指令树并返回结果；最终的执行计划包含了重构查询的全部信息，对查询执行 `EXLAIN EXTENDED`，再执行 `SHOW WARINGS`，可看到重构的查询

#### 关联查询优化器

决定了多表关联的顺序，若不想自己决定的顺序被优化器改变，可以用 `STRAIGHY` 关键字；  
优化器尝试在所有关联顺序中选择一个成本最小的来生成执行计划树，如有可能，它会遍历每一个表然后逐个做嵌套循环，计算每一颗可能的执行计划树的成本；但如果有超过 n 个表关联，需要检查 n 的**阶乘**种，称之为所有可能的执行计划的“搜索空间”，其增长速度非常快，当其很大时，优化器不可能逐一评估每一种顺序的，而是使用**贪婪**搜索的方式查找最优的执行计划；当关联表超过 `optimizer_seacrh_depth` 的限制时，就选择贪婪模式

#### 排序优化

排序成本较高，应尽量避免排序或避免对大量数据排序；  
索引顺序扫描能最快得出有序结果，当不能通过索引排序时，MySQL 则要自己排序；  
若数据量小于“排序缓冲区”，则在内存中进行“快速排序”；数据量大则先将数据分块，对每个独立块使用“快速排序”，并将各个块的排序结果存放在磁盘上，然后再合并；这些统一称为**文件排序**(filesort)

MySQL 有两种排序算法：
* **两次传输排序**（旧版本使用）：
    读取行指针和需要排序的字段，对其排序，然后根据排序结果读取所需数据行；  
    需要从数据表读取两次数据，第二次读取因为是排序后的记录，会产生大量随机 I/O，成本较高，当使用 MyISAM 时，成本更高，因为 MyISAM 使用系统调用进行数据的读取（MyISAM 非常依赖操作系统对数据的缓存）；  
    优点是排序是存储尽可能少的数据，让“排序缓冲区”能容纳更多行数进行排序
* **单次传输排序**（新版本使用）：
    先读取所需的所有列，再根据给定列进行排序，然后直接返回排序结果；  
    在 4.1 版本后引入，对 I/O 密集型应用效率高了很多，只需一次顺序 I/O 读取所有数据，无需随机 I/O；  
    缺点是若所需列很多、很大，会占用大量额外空间，需要拆分更多排序块

两个算法各有优劣，当查询所需列总长度不超过 `max_length_for_sort_data` 时，使用**单次传输排序**

文件排序所需临时存储空间会比实际数据大很多，因为对每个排序记录都会分配**足够长的定长空间**来存放，即 VARCHAR 等变长类型也会分配其完整长度的空间，若使用 UTF-8 字符集，会为每个字符预留三个字节

关联查询时排序分两种情况：
1. 若 ORDER BY 字句中所有列来自第一个表，就在关联处理第一个表是进行文件排序，此时，EXPLAIN 的 Extra 列含有 "Using filesort"；  
2. 其它情况，会先将关联结果存放在临时表中，在所有关联结束后进行文件排序，此时，EXPLAIN 的 Extra 列含有 "Using temporary; Using filesort"；

LIMIT 关键字会在排序之后才应用！但 5.6 版本改进了，当只需返回部分排序结果，例如使用 LIMIT 时，会根据实际情况，舍弃不满足条件的结果再进行排序